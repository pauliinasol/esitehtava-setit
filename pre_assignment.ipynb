{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HoxHunt Summer Hunters 2020 - Data - Home assignment\n",
    "\n",
    "\n",
    "<img src=\"https://www.dropbox.com/s/zmuij2fyjo27j1u/Screenshot%202019-03-21%2017.28.10.png?dl=1\" width=\"1000\">\n",
    "\n",
    "## Assignment\n",
    "\n",
    "In this assignment you as a HoxHunt Data Science Hunter are given the task to extract interesting features from a possible malicious indicator of compromise, more specifically in this case from a given potentially malicious URL. \n",
    "\n",
    "<img src=\"https://www.dropbox.com/s/ao0neaphtfama7g/Screenshot%202019-03-21%2017.23.40.png?dl=1\" width=\"400\">\n",
    "\n",
    "This assignment assumes that you are comfortable (or quick to learn) on using Jupyter Notebooks and suitable programming enviroment such as Python, R or Julia. The example below uses Python and has some external dependencies such as Requests library.\n",
    "\n",
    "Happy hunting!\n",
    "\n",
    "\n",
    "## Interesting research papers & resources\n",
    "\n",
    "Below is a list of interesting research papers on the topic. They might give you good tips what features you could extract from a given URL:\n",
    "\n",
    "\n",
    "[Know Your Phish: Novel Techniques for Detecting\n",
    "Phishing Sites and their Targets](https://arxiv.org/pdf/1510.06501.pdf)\n",
    "\n",
    "[DeltaPhish: Detecting Phishing Webpages\n",
    "in Compromised Websites](https://arxiv.org/pdf/1707.00317.pdf)\n",
    "\n",
    "[PhishAri: Automatic Realtime Phishing Detection on Twitter](https://arxiv.org/pdf/1301.6899.pdf)\n",
    "\n",
    "[More or Less? Predict the Social Influence of Malicious URLs on Social Media\n",
    "](https://arxiv.org/abs/1812.02978)\n",
    "\n",
    "[awesome-threat-intelligence](https://github.com/hslatman/awesome-threat-intelligence)\n",
    "\n",
    "\n",
    "\n",
    "## What we expect\n",
    "\n",
    "Investigate potential features you could extract from the given URL and implement extractors for the ones that interest you the most. Below example code extracts one feature but does not store it very efficiently (just console logs it). Implement sensible data structure using some known data structure library to store the features per URL. Also consider how would you approach error handling if one feature extractor fails?\n",
    "\n",
    "Be prepared to discuss questions such as: what features could indicate the malicousness of a given URL? What goes in to the thinking of the attacker when they are choosing a site for an attack? What would you develop next?\n",
    "\n",
    "## What we don't expect\n",
    "\n",
    "Implement a humangous set of features.\n",
    "\n",
    "Implement any kind of actual predicition models that uses the features to give predictions on malicousness at this stage :) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## My first thoughts\n",
    "\n",
    "\n",
    "Feature engineering is very much about creativity, hence I think it is very valuable when starting to work on a new problem to first try creating features on your own for a few days before diving into other people's approaches or papers. I think seeing how other people have solved a problem before very much steers your thinking into that direction unconsiously. \n",
    "\n",
    "### Type of features that come to mind\n",
    "I can think of a few different types of features one could use for phising url detection:\n",
    "    1. URL based\n",
    "        - Just use the text string of the url to compute things such as url length etc.\n",
    "    2. Page content based\n",
    "        - Get the html file and analyze the page structure for example \"is the metadata field filled?\"\n",
    "    3. Domain based\n",
    "        - When was the domain registered?\n",
    "        - To which country it was registered to?\n",
    "\n",
    "I will mostly focus on the URL based features as if you could make a model work with them I think it would be the best case scenario as the computation is much lighter and we could use the already closed phising domain urls as our data.\n",
    "\n",
    "## Journal\n",
    "    - 21.02 Read the problem, understand what its about and start generating features relying solely on own experience and intuition.\n",
    "    \n",
    "    - 22.02 Beer\n",
    "\n",
    "    - 23.02 Start reading papers for more ideas. Implement Random forests for the academic phising dataset.\n",
    "    \n",
    "    - 24.02 Generate more features.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import json\n",
    "import pandas as pd\n",
    "from urllib.parse import urlparse\n",
    "import re\n",
    "import tldextract as tlde\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore') # Added after we are done to suppress useless warnings.\n",
    "from string import punctuation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "code_folding": [
     0,
     11,
     21,
     31,
     38,
     44,
     48,
     52,
     62,
     68,
     72,
     75,
     81
    ]
   },
   "outputs": [],
   "source": [
    "def get_domain_age_in_days(domain):\n",
    "    show =  \"https://input.payapi.io/v1/api/fraud/domain/age/\" + domain\n",
    "    try:\n",
    "        r = requests.get(show)\n",
    "        r.raise_for_status()\n",
    "        data = r.json()\n",
    "        return data['result'] if 'result' in data else None\n",
    "    except requests.exceptions.RequestException as e:  \n",
    "        return str(e).split(':')[0]\n",
    "    \n",
    "# https://ip-api.com/ is a free geolocation API\n",
    "def get_hosting_country(domain):\n",
    "    show = \"http://ip-api.com/json/\" + domain\n",
    "    try:\n",
    "        r = requests.get(show)\n",
    "        r.raise_for_status()\n",
    "        data = r.json()\n",
    "        return data['country'] if data['status'] == 'success' else data['message']\n",
    "    except requests.exceptions.RequestException as e:  \n",
    "        return str(e).split(':')[0]\n",
    "    \n",
    "def get_org_field(domain):\n",
    "    show = \"http://ip-api.com/json/\" + domain\n",
    "    try:\n",
    "        r = requests.get(show)\n",
    "        r.raise_for_status()\n",
    "        data = r.json()\n",
    "        return data['org'] if data['status'] == 'success' else data['message']\n",
    "    except requests.exceptions.RequestException as e:  \n",
    "        return str(e).split(':')[0]\n",
    "    \n",
    "def parse_domain_from_url(url):\n",
    "    t = urlparse(url).netloc\n",
    "    return '.'.join(t.split('.')[-2:])\n",
    "\n",
    "def remove_prefix(text, prefix):\n",
    "    return text[len(prefix):] if text.startswith(prefix) else text\n",
    "\n",
    "def clean_up_url(url):\n",
    "    prefixes = ['http://', 'https://']\n",
    "    for prefix in prefixes:\n",
    "        url = remove_prefix(url, prefix)\n",
    "    return url\n",
    "\n",
    "def n_non_alphanumerics(string):\n",
    "    return len([char for char in string if not char.isalpha()])\n",
    "\n",
    "#https://www.researchgate.net/publication/333166694_Phishing_URL_detection_system_based_on_URL_features_using_SVM\n",
    "def n_suspicous_chars(string):\n",
    "    return len([char for char in string if char in punctuation])\n",
    "\n",
    "# https://www.wandera.com/top-10-mobile-phishing-techniques/\n",
    "def top_misspelled(domain):\n",
    "    top_misspelled = ['apple-com', 'applecom', 'apple.con', 'appie.com',  'app-le.com',\n",
    "                      'pavpal.com', 'puaypal.com', 'pauypal.com', 'paypal-com', 'paypai.com',\n",
    "                      'wellsf.argo.com', 'Iclod.com', 'icloud-com', '1cloud.com', 'lcloud.com',\n",
    "                      'apple-id', 'apple.id', 'appleld', 'appieid', 'applid',\n",
    "                      'facbook', 'ficebook', 'faceboook', 'facebo0k', 'faceebook',\n",
    "                     'amazo', 'amazn', 'a-mazon', 'amzon', 'microsft', 'gooogle', 'gogle',\n",
    "                     'americaexpress']\n",
    "    return any(misspelled in domain for misspelled in top_misspelled)\n",
    "\n",
    "def top_companies(domain):\n",
    "    companies = ['apple', 'microsoft', 'paypal', 'amazon', 'facebook',\n",
    "                 'americanexpress', 'apple-id', 'icloud']\n",
    "    \n",
    "    return any(company in domain for company in companies)\n",
    "\n",
    "def www_in_middle(domain):\n",
    "    keywords = ['http', 'https', 'www']\n",
    "    return any(kw in domain for kw in keywords)\n",
    "\n",
    "def list_to_string(list_of_strings):\n",
    "    return ' '.join(list_of_strings)\n",
    "\n",
    "def shortened_url(url):\n",
    "    # From: https://www.adweek.com/digital/top-5-url-shorteners-and-3-honorable-mentions/\n",
    "    common = ['bit.ly', 'goo.gl', 'Owl.ly', 'Deck.ly', 'Su.pr',\n",
    "              'fur.ly', 'moourl.com']\n",
    "    return any(x in url for x in common)\n",
    "\n",
    "def split_url_inference(row):\n",
    "    splitted = re.split('[^a-zA-Z]', row['url'])\n",
    "    splitted = [x for x in splitted if x != \"\"]\n",
    "    try:\n",
    "        splitted.remove(row['ps'])\n",
    "        splitted.remove(row['mld'])\n",
    "    except ValueError:\n",
    "        pass\n",
    "    \n",
    "    return splitted\n",
    "\n",
    "def analyze_url(url, api=True):\n",
    "    \n",
    "    # Dictionaries are extremely efficient and optimized in python. Also easy to convert into a Pandas dataframe for predictions.\n",
    "    features = dict()\n",
    "    # First feature, if domain is new it could indicate that the bad guy has bought it recently...\n",
    "    domain = parse_domain_from_url(url)\n",
    "    \n",
    "    # To demonstrate how slow transferring information over the network is \n",
    "    if api:\n",
    "        features['domain_hosting_country'] = get_hosting_country(domain)\n",
    "        features['domain_org_field'] = get_org_field(domain)\n",
    "        features['domain_age_in_days'] = get_domain_age_in_days(domain);\n",
    "    \n",
    "    # Basic features\n",
    "    features['url'] = url\n",
    "    features['url_length'] = len(url)\n",
    "    features['n_numbers_in_url'] = sum(c.isdigit() for c in url)\n",
    "    features['n_dots_in_url'] = url.count('.')\n",
    "    features['n_dashes_in_url'] = url.count('-')\n",
    "    features['https_url'] = url[:5] == 'https'\n",
    "    \n",
    "    ## Remove http, https\n",
    "    features['url'] = clean_up_url(features['url'])\n",
    "    features['begins_with_www'] = features['url'].startswith('www.')\n",
    "    \n",
    "    ## Remove www.\n",
    "    features['url'] = remove_prefix(features['url'], 'www.')\n",
    "    url = features['url']\n",
    "    \n",
    "    # Use the tlde library for extracting the main level domain part and the suffix.\n",
    "    features['ps'] = tlde.extract(url).suffix\n",
    "    features['mld'] = tlde.extract(url).domain\n",
    "    features['mld.ps'] = features['mld'] + '.' + features['ps'] \n",
    "    \n",
    "    # Remaining non alphanumeric parts of the url \n",
    "    features['rem'] = split_url_inference(features)\n",
    "    features['rem_string'] = list_to_string(features['rem'])\n",
    "    \n",
    "    # More basic features\n",
    "    features['n_subdomains'] = len(features['rem'])\n",
    "    features['n_suspicious'] = n_suspicous_chars(url)\n",
    "    features['shortened_url'] = shortened_url(url)\n",
    "    features['n_non_alphanumerics'] = n_non_alphanumerics(url)\n",
    "    features['misspelled'] = top_misspelled(url)\n",
    "    features['popular_companies'] = top_companies(url)\n",
    "    features['redirection'] = '//' in url\n",
    "    features['at_sign'] = '@' in url\n",
    "    features['question_mark'] = '?' in url\n",
    "    features['www_in_middle'] = www_in_middle(url)\n",
    "    \n",
    "    features['in_10mil_most_common'] = common_page(features['mld.ps'])\n",
    "    features['page_ranking'] = page_ranking(features)\n",
    "    \n",
    "    \n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Note some of these urls are live phishing sites (as of 2019-03-21) use with caution! More can be found at https://www.phishtank.com/\n",
    "example_urls = [\"https://www.slideshare.net/weaveworks/client-side-monitoring-with-prometheus\",\n",
    "                \"http://cartaobndes.gov.br.cv31792.tmweb.ru/\",\n",
    "                \"https://paypal.co.uk.yatn.eu/m/\",\n",
    "                \"http://college-eisk.ru/cli/\",\n",
    "                \"https://dotpay-platnosc3.eu/dotpay/\",\n",
    "                \"https://www.facebook.com/\",\n",
    "                \"https://www.nettiauto.com/\"\n",
    "               ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Features\n",
    "\n",
    "One can get a general idea for features with just looking at the data and using ones intuition.\n",
    "\n",
    "### Initial features\n",
    "    - Length of url\n",
    "    - Number of numbers in an url\n",
    "    - Number of dots in url\n",
    "    - Is the url https or http?\n",
    "    - Does the url begin with www.?\n",
    "    - In which country is the domain hosted?\n",
    "    - Under which org is the domain registered?\n",
    "    \n",
    "### Features after gaining some domain knowledge via internet\n",
    "    - Is the URL shortened (e.g bit.ly)?\n",
    "    - Number of dashes in the URL\n",
    "    - Number of slashes in the URL\n",
    "    - Number of non-alphanumeric characters in the URL\n",
    "    - Number of weird characters (!\"#$%&\\'()*+,-./:;<=>?@[\\\\]^_`{|}~)\n",
    "    - Number of double slahes (According to some article this means redirection)\n",
    "    - www, http or https embedded in the middle of the URL\n",
    "    - Is there @ sign in the url --> (@ sign has some special meaning)\n",
    "    - Number of question marks in the URL\n",
    "    \n",
    "    \n",
    "### Key for performance\n",
    "The key revelation for me was to discover the structure of the url and learning that after one has registered a main level domain it cannot be used by other people.\n",
    "\n",
    "For example in the url \"www.google.com\" google.com is a registered domain and it cannot be used as such by the phisers. Phisers then can only try to mask this main level domain part that people won't realise it's not actually Google for example \"google-com.co\"\n",
    "\n",
    "So the key became to extract this main level domain part from the url and check whether that part is found from some source where credible URL:s are listed\n",
    "\n",
    "I used the Open page rank initiative, which has the rating of common domains rated by Google's page rank algorithm. The assumption was that if the page had high rating or atleast was found from the data, there would be quite a high probability that it was not a phising URL."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset of page ranked urls\n",
    "\n",
    "Dataset: https://www.domcop.com/top-10-million-domains\n",
    "\n",
    "This dataset contains the top 10 million domains based on google's page rank algorithm.\n",
    "\n",
    "The assumption is that phising url most likely won't appear in this list.\n",
    "\n",
    "https://www.domcop.com/openpagerank/what-is-openpagerank\n",
    "\n",
    "Let's create a feature that tells us the page rankning of the url or give -1 if the page is not ranked."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "most_common_domains = pd.read_csv('data/top10milliondomains.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Precomputed dictionary\n",
    "\n",
    "We have a 10 million element list of common domains based on their page rank.\n",
    "\n",
    "Since we want to generate features on whether a domain in our dataset is contained in that 10 million elements we need to search operations.\n",
    "\n",
    "Precomputing a Hash Map (Python dict) that contains the domain as key and the ranking of the page as value makes this search million times faster as for hash maps search is O(1) and for lists O(N).\n",
    "\n",
    "\n",
    "With the precomputed dictionary the compute time went from 50 minutes to 50ms."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "ranking_dict = {}\n",
    "def page_ranking(row):\n",
    "        return ranking_dict[row['mld.ps']] if row['in_10mil_most_common'] else -1\n",
    "    \n",
    "def common_page(domain):\n",
    "    return domain in ranking_dict\n",
    "    \n",
    "def make_ranking_dict(row):\n",
    "    ranking_dict[row['Domain']] = row['Open Page Rank']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 4min 1s, sys: 1 s, total: 4min 2s\n",
      "Wall time: 4min 2s\n"
     ]
    }
   ],
   "source": [
    "%%time \n",
    "_ = most_common_domains.apply(make_ranking_dict, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4 minutes to create dict of 10 million elements not too bad.\n",
    "\n",
    "I still prefer to not do this again, hence let's store the dict as a pickle file for fast reloading."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Store the dict as a pickle.\n",
    "with open('data/ranking.pickle', 'wb') as handle:\n",
    "    pickle.dump(ranking_dict, handle, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the dict from the pickle file\n",
    "with open('data/ranking.pickle', 'rb') as handle:\n",
    "    ranking_dict = pickle.load(handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10.0, 3.48)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ranking_dict['twitter.com'], ranking_dict['nettiauto.com']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem with features that require requests\n",
    "\n",
    "One problem I had not thought about before this assignment is the problem of API queried features. \n",
    "\n",
    "When generating features for large dataframes, querying API:s or doing GET request to get page content will slow down the calculations too much.\n",
    "\n",
    "This will result in the fact that queried features would have to be generated online when data is being collected. This makes it hard to leverage Open data that has already been collected by other people. Which is the case in phising urls aswell.\n",
    "\n",
    "I guess it can also solved with huge amount of computational resources, but that's practical for companies such as Google that have infinite computing resources.\n",
    "\n",
    "In the following I will demonstrate the time difference between computing the API features compared to non API features."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Timing with API calls\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "unable to cache TLDs in file /usr/local/lib/python3.6/dist-packages/tldextract/.tld_set: [Errno 13] Permission denied: '/usr/local/lib/python3.6/dist-packages/tldextract/.tld_set'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 505 ms, sys: 19.8 ms, total: 525 ms\n",
      "Wall time: 3.43 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Initialize the DF with the first item\n",
    "url_iter = iter(example_urls)\n",
    "features = analyze_url(next(url_iter))\n",
    "df = pd.DataFrame([list(features.values())], columns=list(features.keys()))\n",
    "\n",
    "for url in url_iter: \n",
    "    features = analyze_url(url)\n",
    "    df = df.append(pd.DataFrame([list(features.values())], columns=list(features.keys())), ignore_index=True)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Timing without API calls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 43.3 ms, sys: 3.84 ms, total: 47.2 ms\n",
      "Wall time: 51.3 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Initialize the DF with the first item\n",
    "url_iter = iter(example_urls)\n",
    "features = analyze_url(next(url_iter), api=False)\n",
    "df = pd.DataFrame([list(features.values())], columns=list(features.keys()))\n",
    "for url in url_iter: \n",
    "    features = analyze_url(url, api=False)\n",
    "    df = df.append(pd.DataFrame([list(features.values())], columns=list(features.keys())), ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "71.42857142857143"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "3.5 / 0.049"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "times faster without querying API:s\n",
    "\n",
    "\n",
    "This would be too slow for any reasonable size dataset.\n",
    "\n",
    "This also shows the power offline features that are just based on the URL string not the page content or other factors. These types of features can be computed drastically faster than features that need to make requests to API:s or even GET the page content."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>url</th>\n",
       "      <th>url_length</th>\n",
       "      <th>n_numbers_in_url</th>\n",
       "      <th>n_dots_in_url</th>\n",
       "      <th>n_dashes_in_url</th>\n",
       "      <th>https_url</th>\n",
       "      <th>begins_with_www</th>\n",
       "      <th>ps</th>\n",
       "      <th>mld</th>\n",
       "      <th>mld.ps</th>\n",
       "      <th>...</th>\n",
       "      <th>shortened_url</th>\n",
       "      <th>n_non_alphanumerics</th>\n",
       "      <th>misspelled</th>\n",
       "      <th>popular_companies</th>\n",
       "      <th>redirection</th>\n",
       "      <th>at_sign</th>\n",
       "      <th>question_mark</th>\n",
       "      <th>www_in_middle</th>\n",
       "      <th>in_10mil_most_common</th>\n",
       "      <th>page_ranking</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>slideshare.net/weaveworks/client-side-monitori...</td>\n",
       "      <td>76</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>net</td>\n",
       "      <td>slideshare</td>\n",
       "      <td>slideshare.net</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>7</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>7.78</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>cartaobndes.gov.br.cv31792.tmweb.ru/</td>\n",
       "      <td>43</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>ru</td>\n",
       "      <td>tmweb</td>\n",
       "      <td>tmweb.ru</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>11</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>-1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>paypal.co.uk.yatn.eu/m/</td>\n",
       "      <td>31</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>eu</td>\n",
       "      <td>yatn</td>\n",
       "      <td>yatn.eu</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>6</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>-1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>college-eisk.ru/cli/</td>\n",
       "      <td>27</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>ru</td>\n",
       "      <td>college-eisk</td>\n",
       "      <td>college-eisk.ru</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>4</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>-1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>dotpay-platnosc3.eu/dotpay/</td>\n",
       "      <td>35</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>eu</td>\n",
       "      <td>dotpay-platnosc3</td>\n",
       "      <td>dotpay-platnosc3.eu</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>5</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>-1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>facebook.com/</td>\n",
       "      <td>25</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>com</td>\n",
       "      <td>facebook</td>\n",
       "      <td>facebook.com</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>2</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>10.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>nettiauto.com/</td>\n",
       "      <td>26</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>com</td>\n",
       "      <td>nettiauto</td>\n",
       "      <td>nettiauto.com</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>2</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>3.48</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7 rows × 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 url  url_length  \\\n",
       "0  slideshare.net/weaveworks/client-side-monitori...          76   \n",
       "1               cartaobndes.gov.br.cv31792.tmweb.ru/          43   \n",
       "2                            paypal.co.uk.yatn.eu/m/          31   \n",
       "3                               college-eisk.ru/cli/          27   \n",
       "4                        dotpay-platnosc3.eu/dotpay/          35   \n",
       "5                                      facebook.com/          25   \n",
       "6                                     nettiauto.com/          26   \n",
       "\n",
       "   n_numbers_in_url  n_dots_in_url  n_dashes_in_url  https_url  \\\n",
       "0                 0              2                4       True   \n",
       "1                 5              5                0      False   \n",
       "2                 0              4                0       True   \n",
       "3                 0              1                1      False   \n",
       "4                 1              1                1       True   \n",
       "5                 0              2                0       True   \n",
       "6                 0              2                0       True   \n",
       "\n",
       "   begins_with_www   ps               mld               mld.ps  ...  \\\n",
       "0             True  net        slideshare       slideshare.net  ...   \n",
       "1            False   ru             tmweb             tmweb.ru  ...   \n",
       "2            False   eu              yatn              yatn.eu  ...   \n",
       "3            False   ru      college-eisk      college-eisk.ru  ...   \n",
       "4            False   eu  dotpay-platnosc3  dotpay-platnosc3.eu  ...   \n",
       "5             True  com          facebook         facebook.com  ...   \n",
       "6             True  com         nettiauto        nettiauto.com  ...   \n",
       "\n",
       "  shortened_url n_non_alphanumerics  misspelled  popular_companies  \\\n",
       "0         False                   7       False              False   \n",
       "1         False                  11       False              False   \n",
       "2         False                   6       False               True   \n",
       "3         False                   4       False              False   \n",
       "4         False                   5       False              False   \n",
       "5         False                   2       False               True   \n",
       "6         False                   2       False              False   \n",
       "\n",
       "   redirection  at_sign  question_mark  www_in_middle  in_10mil_most_common  \\\n",
       "0        False    False          False          False                  True   \n",
       "1        False    False          False          False                 False   \n",
       "2        False    False          False          False                 False   \n",
       "3        False    False          False          False                 False   \n",
       "4        False    False          False          False                 False   \n",
       "5        False    False          False          False                  True   \n",
       "6        False    False          False          False                  True   \n",
       "\n",
       "   page_ranking  \n",
       "0          7.78  \n",
       "1         -1.00  \n",
       "2         -1.00  \n",
       "3         -1.00  \n",
       "4         -1.00  \n",
       "5         10.00  \n",
       "6          3.48  \n",
       "\n",
       "[7 rows x 24 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing the features with a real model\n",
    "\n",
    "I think one of the most important things to do in the beginning of a new ML problem is to get a basic pipeline rolling as soon as possible and test some basic models. This gives you a valuable baseline model that you can compare your other models against. Also with interpretable models such as Random Forest you get an idea on, which features actually work in prediction. This can often be different to what your intuition says.\n",
    "\n",
    "I loaded the Aalto phish storm dataset and decided to try random forest to get some idea, which type of features would work.\n",
    "\n",
    "Dataset: https://research.aalto.fi/en/datasets/phishstorm--phishing--legitimate-url-dataset(f49465b2-c68a-4182-9171-075f0ed797d5).html\n",
    "\n",
    "\n",
    "Paper: https://hal.inria.fr/hal-01092771/document\n",
    "\n",
    "\n",
    "The dataset contains 96005 urls that are labeled as phising and non phising urls.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "b'Skipping line 18259: expected 14 fields, saw 15\\nSkipping line 18273: expected 14 fields, saw 15\\n'\n"
     ]
    }
   ],
   "source": [
    "data = pd.read_csv('data/urlset.csv', encoding='latin', error_bad_lines=False)\n",
    "data = data[['domain', 'label']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'!\"#$%&\\'()*+,-./:;<=>?@[\\\\]^_`{|}~'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "punctuation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "code_folding": [
     0,
     11
    ]
   },
   "outputs": [],
   "source": [
    "def split_url(row):\n",
    "    splitted = re.split('[^a-zA-Z]', row['domain'])\n",
    "    splitted = [x for x in splitted if x != \"\"]\n",
    "    try:\n",
    "        splitted.remove(row['ps'])\n",
    "        splitted.remove(row['mld'])\n",
    "    except ValueError:\n",
    "        pass\n",
    "    \n",
    "    return splitted\n",
    "\n",
    "def extract_domain_parts(data):\n",
    "    data['domain'] = data['domain'].apply(clean_up_url)\n",
    "    data['ps'] = data['domain'].apply(lambda x: tlde.extract(x).suffix)\n",
    "    data['mld'] = data['domain'].apply(lambda x: tlde.extract(x).domain)\n",
    "    data['mld.ps'] = data['domain'].apply(lambda x: tlde.extract(x).domain + '.' + tlde.extract(x).suffix)\n",
    "    data['sld'] = data['domain'].apply(lambda x: tlde.extract(x).subdomain)\n",
    "    data['rem'] = data.apply(split_url, axis=1)\n",
    "    return data\n",
    "\n",
    "def create_features(data):\n",
    "    data['url_length'] = data['domain'].apply(len)\n",
    "    data['n_numbers_in_url'] = data['domain'].apply(lambda url: sum(c.isdigit() for c in url))\n",
    "    data['n_dots_in_url'] = data['domain'].apply(lambda url: url.count('.'))\n",
    "    data['n_dashes_in_url'] = data['domain'].apply(lambda url: url.count('-'))\n",
    "    data['shortened_url'] = data['domain'].apply(shortened_url)\n",
    "    data['n_subdomains'] = data['rem'].apply(len)\n",
    "    data['n_non_alphanumerics'] = data['domain'].apply(n_non_alphanumerics)\n",
    "    data['n_suspicious'] = data['domain'].apply(n_suspicous_chars)\n",
    "    data['misspelled'] = data['domain'].apply(top_misspelled)\n",
    "    data['popular_companies'] = data['domain'].apply(top_companies)\n",
    "    data['redirection'] = data['domain'].apply(lambda url: '//' in url)\n",
    "    data['at_sign'] = data['domain'].apply(lambda url: '@' in url)\n",
    "    data['question_mark'] = data['domain'].apply(lambda url: '?' in url)\n",
    "    data['www_in_middle'] = data['domain'].apply(www_in_middle)\n",
    "    \n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = extract_domain_parts(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>domain</th>\n",
       "      <th>label</th>\n",
       "      <th>ps</th>\n",
       "      <th>mld</th>\n",
       "      <th>mld.ps</th>\n",
       "      <th>sld</th>\n",
       "      <th>rem</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>nobell.it/70ffb52d079109dca5664cce6f317373782/...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>it</td>\n",
       "      <td>nobell</td>\n",
       "      <td>nobell.it</td>\n",
       "      <td></td>\n",
       "      <td>[ffb, d, dca, cce, f, login, SkyPe, com, en, c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>www.dghjdgf.com/paypal.co.uk/cycgi-bin/webscrc...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>com</td>\n",
       "      <td>dghjdgf</td>\n",
       "      <td>dghjdgf.com</td>\n",
       "      <td>www</td>\n",
       "      <td>[www, paypal, co, uk, cycgi, bin, webscrcmd, h...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>serviciosbys.com/paypal.cgi.bin.get-into.herf....</td>\n",
       "      <td>1.0</td>\n",
       "      <td>com</td>\n",
       "      <td>serviciosbys</td>\n",
       "      <td>serviciosbys.com</td>\n",
       "      <td></td>\n",
       "      <td>[paypal, cgi, bin, get, into, herf, secure, di...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>mail.printakid.com/www.online.americanexpress....</td>\n",
       "      <td>1.0</td>\n",
       "      <td>com</td>\n",
       "      <td>printakid</td>\n",
       "      <td>printakid.com</td>\n",
       "      <td>mail</td>\n",
       "      <td>[mail, www, online, americanexpress, com, inde...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>thewhiskeydregs.com/wp-content/themes/widescre...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>com</td>\n",
       "      <td>thewhiskeydregs</td>\n",
       "      <td>thewhiskeydregs.com</td>\n",
       "      <td></td>\n",
       "      <td>[wp, content, themes, widescreen, includes, te...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              domain  label   ps  \\\n",
       "0  nobell.it/70ffb52d079109dca5664cce6f317373782/...    1.0   it   \n",
       "1  www.dghjdgf.com/paypal.co.uk/cycgi-bin/webscrc...    1.0  com   \n",
       "2  serviciosbys.com/paypal.cgi.bin.get-into.herf....    1.0  com   \n",
       "3  mail.printakid.com/www.online.americanexpress....    1.0  com   \n",
       "4  thewhiskeydregs.com/wp-content/themes/widescre...    1.0  com   \n",
       "\n",
       "               mld               mld.ps   sld  \\\n",
       "0           nobell            nobell.it         \n",
       "1          dghjdgf          dghjdgf.com   www   \n",
       "2     serviciosbys     serviciosbys.com         \n",
       "3        printakid        printakid.com  mail   \n",
       "4  thewhiskeydregs  thewhiskeydregs.com         \n",
       "\n",
       "                                                 rem  \n",
       "0  [ffb, d, dca, cce, f, login, SkyPe, com, en, c...  \n",
       "1  [www, paypal, co, uk, cycgi, bin, webscrcmd, h...  \n",
       "2  [paypal, cgi, bin, get, into, herf, secure, di...  \n",
       "3  [mail, www, online, americanexpress, com, inde...  \n",
       "4  [wp, content, themes, widescreen, includes, te...  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TFIDFVectorizer\n",
    "\n",
    "Phising urls use certain keywords such as login to trick users to click to their sites.\n",
    "\n",
    "Let's count, which words appear the most in our dataset and use this information as a feature.\n",
    "\n",
    "Very effective and common method for this kind of term frequency analysis is tfid algorithm.\n",
    "\n",
    "https://en.wikipedia.org/wiki/Tf%E2%80%93idf\n",
    "\n",
    "Sklearn has a nice implementation of this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "\n",
    "\n",
    "def tfidf_features(corpus):\n",
    "    tfv = TfidfVectorizer(min_df=2,  max_features=None,\n",
    "        strip_accents='unicode', analyzer='word', token_pattern=r'(?u)\\b\\w+\\b',\n",
    "        ngram_range=(1, 3), use_idf=1, smooth_idf=1, sublinear_tf=1,)\n",
    "    tfv.fit(list(corpus))\n",
    "    X = tfv.transform(corpus)\n",
    "    return X\n",
    "    \n",
    "def svd_features(df, freq_matrix, n_comps=20):\n",
    "    svd = TruncatedSVD(n_components=n_comps) #Choose 20 most relevant ones.\n",
    "    svd.fit(freq_matrix)\n",
    "    freq_matrix = svd.transform(freq_matrix)\n",
    "    freq_matrix = pd.DataFrame(freq_matrix, columns=['svd_{}'.format(i) for i in range(n_comps)])\n",
    "    df = pd.concat((df, freq_matrix), axis=1)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the list of strings into a single string\n",
    "data['rem_string'] = data['rem'].apply(list_to_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 6.13 s, sys: 84 ms, total: 6.21 s\n",
      "Wall time: 6.21 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Create a corpus and run the tfidf algorithm.\n",
    "corpus = list(data['rem_string'])\n",
    "X = tfidf_features(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(96005, 128694)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vectorizer results in a sparse matrix that has a column for each of the words appearing in the corpus. \n",
    "\n",
    "Let's use SVD to extract the most information dense part of this matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 7.38 s, sys: 2.55 s, total: 9.93 s\n",
      "Wall time: 3.83 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "data = svd_features(data, X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 53.7 ms, sys: 38 µs, total: 53.8 ms\n",
      "Wall time: 53.6 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "data['in_10mil_most_common'] = data['mld.ps'].apply(common_page)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1.96 s, sys: 28 ms, total: 1.98 s\n",
      "Wall time: 1.98 s\n"
     ]
    }
   ],
   "source": [
    "%%time \n",
    "data['page_ranking'] = data.apply(page_ranking, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_data = create_features(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_data.to_pickle('data/final.pickle')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Store the final feature engineered dataframe as pickle for fast reload."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_data = pd.read_pickle('data/final.pickle')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_data = final_data.drop(['ps', 'mld', 'mld.ps', 'sld', 'rem', 'rem_string'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "domain                   0\n",
       "label                   92\n",
       "svd_0                    0\n",
       "svd_1                    0\n",
       "svd_2                    0\n",
       "svd_3                    0\n",
       "svd_4                    0\n",
       "svd_5                    0\n",
       "svd_6                    0\n",
       "svd_7                    0\n",
       "svd_8                    0\n",
       "svd_9                    0\n",
       "svd_10                   0\n",
       "svd_11                   0\n",
       "svd_12                   0\n",
       "svd_13                   0\n",
       "svd_14                   0\n",
       "svd_15                   0\n",
       "svd_16                   0\n",
       "svd_17                   0\n",
       "svd_18                   0\n",
       "svd_19                   0\n",
       "in_10mil_most_common     0\n",
       "page_ranking             0\n",
       "url_length               0\n",
       "n_numbers_in_url         0\n",
       "n_dots_in_url            0\n",
       "n_dashes_in_url          0\n",
       "shortened_url            0\n",
       "n_subdomains             0\n",
       "n_non_alphanumerics      0\n",
       "n_suspicious             0\n",
       "misspelled               0\n",
       "popular_companies        0\n",
       "redirection              0\n",
       "at_sign                  0\n",
       "question_mark            0\n",
       "www_in_middle            0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_data.isnull().sum(axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some label columns are null, hence we should drop them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_data = final_data.dropna(subset=['label'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random forests\n",
    "\n",
    "Random forests is always my first go to algorithm for tabular data problems.\n",
    "\n",
    "It works well most of the time with very little parameter tuning.\n",
    "\n",
    "Even for problems where a more complex model is needed, I still start with Random Forests as it provides a nice model to benchmark the performance of other models to.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = final_data['label']\n",
    "X = final_data.drop(['label', 'domain'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_valid, y_train, y_valid = train_test_split(X, y, test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((64261, 36), (64261,), (31652, 36), (31652,))"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape, y_train.shape, X_valid.shape, y_valid.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = RandomForestClassifier(n_estimators=500, max_features='log2', random_state=42,\n",
    "                           min_samples_leaf=1, n_jobs=-1);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "m.fit(X_train, y_train);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Interpretability of Random Forests\n",
    "\n",
    "One of the best features of Random Forests is that it provides you with feature importance.\n",
    "\n",
    "This tells us, which features were most influental in making the prediction. Which can be key in some applications that require reasons for the predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rf_feature_importance(df, m):\n",
    "    df = pd.DataFrame({'cols' : df.columns, 'imp' : m.feature_importances_}).sort_values('imp', ascending=False)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "fi = rf_feature_importance(X_train, m)\n",
    "fi.plot('cols', 'imp', kind='barh', legend=False, figsize=(14,8));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = m.predict(X_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9698913180841653"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_valid, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "97% WOW!\n",
    "\n",
    "In the paper they achieved 94.91% accuracy with very complex feature engineering, granted we are not using the same validation set, so the results are not completely comparable.\n",
    "\n",
    "Almost makes me think that there's something fishy going on with the model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the Feature importance plot it seems like some features are not contributing at all. We could drop  these and it can improve perf a tiny bit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "to_keep = fi[fi.imp>0.001].cols; len(to_keep)\n",
    "X_train = X_train[to_keep].copy()\n",
    "X_valid = X_valid[to_keep].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "m.fit(X_train, y_train);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = m.predict(X_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9698913180841653"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_valid, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analyze missclassified instances\n",
    "\n",
    "Analyzing the domain names of missclassified instances can give us ideas for new features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "missclassified = X_valid[y_pred != y_valid].index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "missed = final_data.iloc[missclassified]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>domain</th>\n",
       "      <th>label</th>\n",
       "      <th>svd_0</th>\n",
       "      <th>svd_1</th>\n",
       "      <th>svd_2</th>\n",
       "      <th>svd_3</th>\n",
       "      <th>svd_4</th>\n",
       "      <th>svd_5</th>\n",
       "      <th>svd_6</th>\n",
       "      <th>svd_7</th>\n",
       "      <th>...</th>\n",
       "      <th>shortened_url</th>\n",
       "      <th>n_subdomains</th>\n",
       "      <th>n_non_alphanumerics</th>\n",
       "      <th>n_suspicious</th>\n",
       "      <th>misspelled</th>\n",
       "      <th>popular_companies</th>\n",
       "      <th>redirection</th>\n",
       "      <th>at_sign</th>\n",
       "      <th>question_mark</th>\n",
       "      <th>www_in_middle</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>16987</th>\n",
       "      <td>www.properties-us.com/</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.127701</td>\n",
       "      <td>-0.033119</td>\n",
       "      <td>0.042614</td>\n",
       "      <td>-0.025238</td>\n",
       "      <td>-0.022140</td>\n",
       "      <td>-0.004160</td>\n",
       "      <td>0.005563</td>\n",
       "      <td>-0.003549</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5671</th>\n",
       "      <td>livechat26.volusion.com/livechat.aspx?ID=11805...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000885</td>\n",
       "      <td>-0.000158</td>\n",
       "      <td>0.001137</td>\n",
       "      <td>0.001031</td>\n",
       "      <td>-0.000025</td>\n",
       "      <td>0.006422</td>\n",
       "      <td>-0.000113</td>\n",
       "      <td>0.002683</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>15</td>\n",
       "      <td>39</td>\n",
       "      <td>19</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11689</th>\n",
       "      <td>gone-film.com//NAB/index.htm</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.025136</td>\n",
       "      <td>-0.005394</td>\n",
       "      <td>0.052671</td>\n",
       "      <td>0.012442</td>\n",
       "      <td>0.194493</td>\n",
       "      <td>-0.012746</td>\n",
       "      <td>0.044205</td>\n",
       "      <td>0.035710</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4731</th>\n",
       "      <td>ppf.udsu.ru/english/language/itau.atualizar/</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.001645</td>\n",
       "      <td>-0.000351</td>\n",
       "      <td>0.000707</td>\n",
       "      <td>0.000637</td>\n",
       "      <td>0.003091</td>\n",
       "      <td>0.000803</td>\n",
       "      <td>0.001437</td>\n",
       "      <td>0.000384</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>5</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36790</th>\n",
       "      <td>paypal.com.ca.cgi.bin.webscr.cmd.flow.help.wld...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.004086</td>\n",
       "      <td>-0.000551</td>\n",
       "      <td>0.024827</td>\n",
       "      <td>0.009328</td>\n",
       "      <td>-0.000666</td>\n",
       "      <td>0.127384</td>\n",
       "      <td>0.041416</td>\n",
       "      <td>-0.038538</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>37</td>\n",
       "      <td>69</td>\n",
       "      <td>19</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11165</th>\n",
       "      <td>7rk.r.mailjet.com/VAi5sa9A/TuHvx/4q8rHM/www-da...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.037960</td>\n",
       "      <td>-0.009566</td>\n",
       "      <td>0.008794</td>\n",
       "      <td>-0.002065</td>\n",
       "      <td>-0.005403</td>\n",
       "      <td>0.033719</td>\n",
       "      <td>-0.001703</td>\n",
       "      <td>0.008444</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>12</td>\n",
       "      <td>16</td>\n",
       "      <td>11</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10831</th>\n",
       "      <td>www.ipafootcare.org/hayhay.html</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.736208</td>\n",
       "      <td>0.088293</td>\n",
       "      <td>-0.017745</td>\n",
       "      <td>0.575847</td>\n",
       "      <td>-0.082790</td>\n",
       "      <td>-0.050204</td>\n",
       "      <td>-0.207811</td>\n",
       "      <td>-0.169468</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21709</th>\n",
       "      <td>www.xmadwater.com.cn/js?amp</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.058622</td>\n",
       "      <td>-0.015004</td>\n",
       "      <td>0.044810</td>\n",
       "      <td>-0.011244</td>\n",
       "      <td>-0.013731</td>\n",
       "      <td>0.016592</td>\n",
       "      <td>-0.003754</td>\n",
       "      <td>0.006967</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11464</th>\n",
       "      <td>www4049u.sakura.ne.jp/index.htm</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.069729</td>\n",
       "      <td>-0.017160</td>\n",
       "      <td>0.035189</td>\n",
       "      <td>0.002815</td>\n",
       "      <td>0.135975</td>\n",
       "      <td>-0.004564</td>\n",
       "      <td>0.031259</td>\n",
       "      <td>0.032976</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>7</td>\n",
       "      <td>9</td>\n",
       "      <td>5</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10946</th>\n",
       "      <td>ragnasexy.com/job/tabela1/fip1/</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000051</td>\n",
       "      <td>-0.000008</td>\n",
       "      <td>0.000007</td>\n",
       "      <td>0.000047</td>\n",
       "      <td>-0.000027</td>\n",
       "      <td>0.000072</td>\n",
       "      <td>-0.000081</td>\n",
       "      <td>0.000115</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>494 rows × 38 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  domain  label     svd_0  \\\n",
       "16987                             www.properties-us.com/    1.0  0.127701   \n",
       "5671   livechat26.volusion.com/livechat.aspx?ID=11805...    1.0  0.000885   \n",
       "11689                       gone-film.com//NAB/index.htm    1.0  0.025136   \n",
       "4731        ppf.udsu.ru/english/language/itau.atualizar/    1.0  0.001645   \n",
       "36790  paypal.com.ca.cgi.bin.webscr.cmd.flow.help.wld...    1.0  0.004086   \n",
       "...                                                  ...    ...       ...   \n",
       "11165  7rk.r.mailjet.com/VAi5sa9A/TuHvx/4q8rHM/www-da...    1.0  0.037960   \n",
       "10831                    www.ipafootcare.org/hayhay.html    1.0  0.736208   \n",
       "21709                        www.xmadwater.com.cn/js?amp    1.0  0.058622   \n",
       "11464                    www4049u.sakura.ne.jp/index.htm    1.0  0.069729   \n",
       "10946                    ragnasexy.com/job/tabela1/fip1/    1.0  0.000051   \n",
       "\n",
       "          svd_1     svd_2     svd_3     svd_4     svd_5     svd_6     svd_7  \\\n",
       "16987 -0.033119  0.042614 -0.025238 -0.022140 -0.004160  0.005563 -0.003549   \n",
       "5671  -0.000158  0.001137  0.001031 -0.000025  0.006422 -0.000113  0.002683   \n",
       "11689 -0.005394  0.052671  0.012442  0.194493 -0.012746  0.044205  0.035710   \n",
       "4731  -0.000351  0.000707  0.000637  0.003091  0.000803  0.001437  0.000384   \n",
       "36790 -0.000551  0.024827  0.009328 -0.000666  0.127384  0.041416 -0.038538   \n",
       "...         ...       ...       ...       ...       ...       ...       ...   \n",
       "11165 -0.009566  0.008794 -0.002065 -0.005403  0.033719 -0.001703  0.008444   \n",
       "10831  0.088293 -0.017745  0.575847 -0.082790 -0.050204 -0.207811 -0.169468   \n",
       "21709 -0.015004  0.044810 -0.011244 -0.013731  0.016592 -0.003754  0.006967   \n",
       "11464 -0.017160  0.035189  0.002815  0.135975 -0.004564  0.031259  0.032976   \n",
       "10946 -0.000008  0.000007  0.000047 -0.000027  0.000072 -0.000081  0.000115   \n",
       "\n",
       "       ...  shortened_url  n_subdomains  n_non_alphanumerics  n_suspicious  \\\n",
       "16987  ...          False             3                    4             4   \n",
       "5671   ...          False            15                   39            19   \n",
       "11689  ...          False             5                    6             6   \n",
       "4731   ...          False             5                    7             7   \n",
       "36790  ...          False            37                   69            19   \n",
       "...    ...            ...           ...                  ...           ...   \n",
       "11165  ...          False            12                   16            11   \n",
       "10831  ...          False             3                    4             4   \n",
       "21709  ...          False             6                    5             5   \n",
       "11464  ...          False             7                    9             5   \n",
       "10946  ...          False             3                    7             5   \n",
       "\n",
       "       misspelled  popular_companies  redirection  at_sign  question_mark  \\\n",
       "16987       False              False        False    False          False   \n",
       "5671        False              False        False    False           True   \n",
       "11689       False              False         True    False          False   \n",
       "4731        False              False        False    False          False   \n",
       "36790       False               True        False    False           True   \n",
       "...           ...                ...          ...      ...            ...   \n",
       "11165       False              False        False    False          False   \n",
       "10831       False              False        False    False          False   \n",
       "21709       False              False        False    False           True   \n",
       "11464       False              False        False    False          False   \n",
       "10946       False              False        False    False          False   \n",
       "\n",
       "       www_in_middle  \n",
       "16987           True  \n",
       "5671           False  \n",
       "11689          False  \n",
       "4731           False  \n",
       "36790          False  \n",
       "...              ...  \n",
       "11165           True  \n",
       "10831           True  \n",
       "21709           True  \n",
       "11464           True  \n",
       "10946          False  \n",
       "\n",
       "[494 rows x 38 columns]"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "missed[missed['label'] == 1.0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These instances were falsely classified as non phising urls."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>domain</th>\n",
       "      <th>label</th>\n",
       "      <th>svd_0</th>\n",
       "      <th>svd_1</th>\n",
       "      <th>svd_2</th>\n",
       "      <th>svd_3</th>\n",
       "      <th>svd_4</th>\n",
       "      <th>svd_5</th>\n",
       "      <th>svd_6</th>\n",
       "      <th>svd_7</th>\n",
       "      <th>...</th>\n",
       "      <th>shortened_url</th>\n",
       "      <th>n_subdomains</th>\n",
       "      <th>n_non_alphanumerics</th>\n",
       "      <th>n_suspicious</th>\n",
       "      <th>misspelled</th>\n",
       "      <th>popular_companies</th>\n",
       "      <th>redirection</th>\n",
       "      <th>at_sign</th>\n",
       "      <th>question_mark</th>\n",
       "      <th>www_in_middle</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>52135</th>\n",
       "      <td>www.pvri.com/products/omnia/</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.215049</td>\n",
       "      <td>-0.055011</td>\n",
       "      <td>-0.017567</td>\n",
       "      <td>-0.022083</td>\n",
       "      <td>-0.017789</td>\n",
       "      <td>-0.002806</td>\n",
       "      <td>0.015448</td>\n",
       "      <td>0.013303</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48358</th>\n",
       "      <td>personal.smartt.com/~brianp</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000896</td>\n",
       "      <td>-0.000085</td>\n",
       "      <td>0.000268</td>\n",
       "      <td>0.001090</td>\n",
       "      <td>0.001087</td>\n",
       "      <td>0.001046</td>\n",
       "      <td>-0.000142</td>\n",
       "      <td>-0.001082</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50186</th>\n",
       "      <td>home.scarlet.be/~tsh36287/</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.002405</td>\n",
       "      <td>0.000249</td>\n",
       "      <td>0.002453</td>\n",
       "      <td>0.009510</td>\n",
       "      <td>0.013928</td>\n",
       "      <td>0.010920</td>\n",
       "      <td>-0.000014</td>\n",
       "      <td>-0.017123</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>5</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65775</th>\n",
       "      <td>tools.ietf.org/html/rfc2553</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.233380</td>\n",
       "      <td>0.966478</td>\n",
       "      <td>-0.010184</td>\n",
       "      <td>-0.104539</td>\n",
       "      <td>0.001419</td>\n",
       "      <td>0.005130</td>\n",
       "      <td>0.014979</td>\n",
       "      <td>0.011434</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52733</th>\n",
       "      <td>www.webspawner.com/users/kinneyr/</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.162418</td>\n",
       "      <td>-0.041753</td>\n",
       "      <td>-0.013055</td>\n",
       "      <td>-0.019741</td>\n",
       "      <td>-0.014782</td>\n",
       "      <td>-0.000542</td>\n",
       "      <td>0.007897</td>\n",
       "      <td>0.006107</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85917</th>\n",
       "      <td>tuxmobil.org/wearables.html</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.034854</td>\n",
       "      <td>0.043393</td>\n",
       "      <td>0.005587</td>\n",
       "      <td>0.124202</td>\n",
       "      <td>-0.002178</td>\n",
       "      <td>-0.009161</td>\n",
       "      <td>-0.042713</td>\n",
       "      <td>-0.035716</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51799</th>\n",
       "      <td>icefishinglight.homestead.com/higlow.html</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.228706</td>\n",
       "      <td>0.285034</td>\n",
       "      <td>0.036688</td>\n",
       "      <td>0.814773</td>\n",
       "      <td>-0.014240</td>\n",
       "      <td>-0.060027</td>\n",
       "      <td>-0.280147</td>\n",
       "      <td>-0.234164</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49336</th>\n",
       "      <td>www.freewebs.com/cp-enterprises/</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.094469</td>\n",
       "      <td>-0.024524</td>\n",
       "      <td>-0.007821</td>\n",
       "      <td>-0.014022</td>\n",
       "      <td>-0.012330</td>\n",
       "      <td>0.002157</td>\n",
       "      <td>0.000906</td>\n",
       "      <td>0.007615</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62752</th>\n",
       "      <td>mathbits.com/MathBits/TISection/Openpage.htm</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.112853</td>\n",
       "      <td>-0.036533</td>\n",
       "      <td>0.095975</td>\n",
       "      <td>-0.135447</td>\n",
       "      <td>0.897714</td>\n",
       "      <td>0.029802</td>\n",
       "      <td>-0.267439</td>\n",
       "      <td>-0.142910</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50904</th>\n",
       "      <td>www.pacificagencies.com/index.htm</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.196784</td>\n",
       "      <td>-0.047110</td>\n",
       "      <td>0.102517</td>\n",
       "      <td>0.037619</td>\n",
       "      <td>0.419970</td>\n",
       "      <td>-0.039271</td>\n",
       "      <td>0.184929</td>\n",
       "      <td>0.144665</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>459 rows × 38 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             domain  label     svd_0  \\\n",
       "52135                  www.pvri.com/products/omnia/    0.0  0.215049   \n",
       "48358                   personal.smartt.com/~brianp    0.0  0.000896   \n",
       "50186                    home.scarlet.be/~tsh36287/    0.0  0.002405   \n",
       "65775                   tools.ietf.org/html/rfc2553    0.0  0.233380   \n",
       "52733             www.webspawner.com/users/kinneyr/    0.0  0.162418   \n",
       "...                                             ...    ...       ...   \n",
       "85917                   tuxmobil.org/wearables.html    0.0  0.034854   \n",
       "51799     icefishinglight.homestead.com/higlow.html    0.0  0.228706   \n",
       "49336              www.freewebs.com/cp-enterprises/    0.0  0.094469   \n",
       "62752  mathbits.com/MathBits/TISection/Openpage.htm    0.0  0.112853   \n",
       "50904             www.pacificagencies.com/index.htm    0.0  0.196784   \n",
       "\n",
       "          svd_1     svd_2     svd_3     svd_4     svd_5     svd_6     svd_7  \\\n",
       "52135 -0.055011 -0.017567 -0.022083 -0.017789 -0.002806  0.015448  0.013303   \n",
       "48358 -0.000085  0.000268  0.001090  0.001087  0.001046 -0.000142 -0.001082   \n",
       "50186  0.000249  0.002453  0.009510  0.013928  0.010920 -0.000014 -0.017123   \n",
       "65775  0.966478 -0.010184 -0.104539  0.001419  0.005130  0.014979  0.011434   \n",
       "52733 -0.041753 -0.013055 -0.019741 -0.014782 -0.000542  0.007897  0.006107   \n",
       "...         ...       ...       ...       ...       ...       ...       ...   \n",
       "85917  0.043393  0.005587  0.124202 -0.002178 -0.009161 -0.042713 -0.035716   \n",
       "51799  0.285034  0.036688  0.814773 -0.014240 -0.060027 -0.280147 -0.234164   \n",
       "49336 -0.024524 -0.007821 -0.014022 -0.012330  0.002157  0.000906  0.007615   \n",
       "62752 -0.036533  0.095975 -0.135447  0.897714  0.029802 -0.267439 -0.142910   \n",
       "50904 -0.047110  0.102517  0.037619  0.419970 -0.039271  0.184929  0.144665   \n",
       "\n",
       "       ...  shortened_url  n_subdomains  n_non_alphanumerics  n_suspicious  \\\n",
       "52135  ...          False             3                    5             5   \n",
       "48358  ...          False             2                    4             4   \n",
       "50186  ...          False             2                   10             5   \n",
       "65775  ...          False             3                    8             4   \n",
       "52733  ...          False             3                    5             5   \n",
       "...    ...            ...           ...                  ...           ...   \n",
       "85917  ...          False             2                    3             3   \n",
       "51799  ...          False             3                    4             4   \n",
       "49336  ...          False             3                    5             5   \n",
       "62752  ...          False             4                    5             5   \n",
       "50904  ...          False             3                    4             4   \n",
       "\n",
       "       misspelled  popular_companies  redirection  at_sign  question_mark  \\\n",
       "52135       False              False        False    False          False   \n",
       "48358       False              False        False    False          False   \n",
       "50186       False              False        False    False          False   \n",
       "65775       False              False        False    False          False   \n",
       "52733       False              False        False    False          False   \n",
       "...           ...                ...          ...      ...            ...   \n",
       "85917       False              False        False    False          False   \n",
       "51799       False              False        False    False          False   \n",
       "49336       False              False        False    False          False   \n",
       "62752       False              False        False    False          False   \n",
       "50904       False              False        False    False          False   \n",
       "\n",
       "       www_in_middle  \n",
       "52135           True  \n",
       "48358          False  \n",
       "50186          False  \n",
       "65775          False  \n",
       "52733           True  \n",
       "...              ...  \n",
       "85917          False  \n",
       "51799          False  \n",
       "49336           True  \n",
       "62752          False  \n",
       "50904           True  \n",
       "\n",
       "[459 rows x 38 columns]"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "missed[missed['label'] == 0.0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These instances were falsely classified as phising urls"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Raw Cell Format",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
